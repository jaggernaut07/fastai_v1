{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from nb_005 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carvana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(See final section of notebook for one-time data processing steps.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/carvana')\n",
    "PATH_PNG = PATH/'train_masks_png'\n",
    "PATH_X_FULL = PATH/'train'\n",
    "PATH_X_128 = PATH/'train-128'\n",
    "PATH_Y_FULL = PATH_PNG\n",
    "PATH_Y_128 = PATH/'train_masks-128'\n",
    "\n",
    "# start with the 128x128 images\n",
    "PATH_X = PATH_X_128\n",
    "PATH_Y = PATH_Y_128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_f = next(PATH_X.iterdir())\n",
    "x = open_image(img_f)\n",
    "x.show()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageMask(Image):\n",
    "    def lighting(self, func, *args, **kwargs): return self\n",
    "    \n",
    "    def refresh(self):\n",
    "        self.sample_kwargs['mode'] = 'nearest'\n",
    "        return super().refresh()\n",
    "\n",
    "def open_mask(fn):\n",
    "    return ImageMask(pil2tensor(PIL.Image.open(fn)).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_fn(x_fn): return PATH_Y/f'{x_fn.name[:-4]}_mask.png'\n",
    "\n",
    "img_y_f = get_y_fn(img_f)\n",
    "y = open_mask(img_y_f)\n",
    "y.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as `show_image`, but renamed with _ prefix\n",
    "def _show_image(img, ax=None, figsize=(3,3), hide_axis=True, cmap='binary', alpha=None):\n",
    "    if ax is None: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(image2np(img), cmap=cmap, alpha=alpha)\n",
    "    if hide_axis: ax.axis('off')\n",
    "    return ax\n",
    "\n",
    "def show_image(x, y=None, ax=None, figsize=(3,3), alpha=0.4, hide_axis=True, cmap='viridis'):\n",
    "    ax1 = _show_image(x, ax=ax, hide_axis=hide_axis, cmap=cmap)\n",
    "    if y is not None: _show_image(y, ax=ax1, alpha=alpha, hide_axis=hide_axis, cmap=cmap)\n",
    "    if hide_axis: ax1.axis('off')\n",
    "        \n",
    "def _show(self, ax=None, y=None, **kwargs):\n",
    "    if y is not None: y=y.data\n",
    "    return show_image(self.data, ax=ax, y=y, **kwargs)\n",
    "\n",
    "Image.show = _show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.show(y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xy transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data types: regr, class, seg, bbox, polygon, generative (s/res, color), custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DatasetTfm(Dataset):\n",
    "    def __init__(self, ds:Dataset,tfms:Collection[Callable]=None,tfm_y:bool=False, **kwargs):\n",
    "        self.ds,self.tfms,self.tfm_y,self.x_kwargs = ds,tfms,tfm_y,kwargs\n",
    "        self.y_kwargs = {**self.x_kwargs, 'do_resolve':False} # don't reset random vars\n",
    "        \n",
    "    def __len__(self): return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        x,y = self.ds[idx]\n",
    "        \n",
    "        x = apply_tfms(self.tfms, x, **self.x_kwargs)\n",
    "        if self.tfm_y: y = apply_tfms(self.tfms, y, **self.y_kwargs)\n",
    "        return x, y\n",
    "    \n",
    "    @property\n",
    "    def c(self): return self.ds.c\n",
    "    \n",
    "import nb_002b,nb_005\n",
    "nb_002b.DatasetTfm = DatasetTfm  \n",
    "nb_005.DatasetTfm  = DatasetTfm  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class MatchedFilesDataset(Dataset):\n",
    "    x_fns:List[Path]; y_fns:List[Path]\n",
    "    def __post_init__(self): assert len(self.x_fns)==len(self.y_fns)\n",
    "    def __repr__(self): return f'{type(self).__name__} of len {len(self.x_fns)}'\n",
    "    def __len__(self): return len(self.x_fns)\n",
    "    def __getitem__(self, i): \n",
    "        return open_image(self.x_fns[i]), open_mask(self.y_fns[i])\n",
    "    \n",
    "def split_arrs_by_idx(idxs, *a):\n",
    "    \"\"\"\n",
    "    Split each array passed as *a, to a pair of arrays like this (elements selected by idxs,  the remaining elements)\n",
    "    This can be used to split multiple arrays containing training data to validation and training set.\n",
    "    :param idxs [int]: list of indexes selected\n",
    "    :param a list: list of np.array, each array should have same amount of elements in the first dimension\n",
    "    :return: list of tuples, each containing a split of corresponding array from *a.\n",
    "            First element of each tuple is an array composed from elements selected by idxs,\n",
    "            second element is an array of remaining elements.\n",
    "    \"\"\"\n",
    "    mask = np.zeros(len(a[0]),dtype=bool)\n",
    "    mask[np.array(idxs)] = True\n",
    "    return [(o[mask],o[~mask]) for o in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fns = [o for o in PATH_X.iterdir() if o.is_file()]\n",
    "y_fns = [get_y_fn(o) for o in x_fns]\n",
    "val_idxs = list(range(1008))\n",
    "((val_x,trn_x),(val_y,trn_y)) = split_arrs_by_idx(val_idxs, np.array(x_fns), np.array(y_fns))\n",
    "train_ds = MatchedFilesDataset(trn_x, trn_y)\n",
    "valid_ds = MatchedFilesDataset(val_x, val_y)\n",
    "train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(train_ds))\n",
    "x.shape, y.shape, type(x), type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=128\n",
    "tfms = get_transforms(do_flip=True, max_rotate=20, max_zoom=2., max_lighting=0.7, max_warp=0.3,p_affine=0.75)\n",
    "train_tds, valid_tds, augm_tds = transform_datasets(train_ds, valid_ds, tfms, tfm_y=True, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(1,4, figsize=(12,6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    imgx,imgy = train_tds[i]\n",
    "    imgx.show(ax, y=imgy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def normalize_batch(b, mean, std, do_y=False):\n",
    "    x,y = b\n",
    "    x = normalize(x,mean,std)\n",
    "    if do_y: y = normalize(y,mean,std)\n",
    "    return x,y\n",
    "\n",
    "def normalize_funcs(mean, std, do_y=False, device=None):\n",
    "    if device is None: device=default_device\n",
    "    return (partial(normalize_batch, mean=mean.to(device),std=std.to(device), do_y=do_y),\n",
    "            partial(denormalize,     mean=mean,           std=std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagenet mean/std\n",
    "default_mean, default_std = tensor([0.485, 0.456, 0.406]), tensor([0.229, 0.224, 0.225])\n",
    "default_norm,default_denorm = normalize_funcs(default_mean,default_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "data = DataBunch.create(train_tds, valid_tds, bs=bs, dl_tfms=default_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_xy_images(x,y,rows,figsize=(9,9)):\n",
    "    fig, axs = plt.subplots(rows,rows,figsize=figsize)\n",
    "    for i, ax in enumerate(axs.flatten()): show_image(x[i], y=y[i], ax=ax)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(data.train_dl))\n",
    "x,y = x.cpu(),y.cpu()\n",
    "x = default_denorm(x)\n",
    "show_xy_images(x,y,6, figsize=(9,9))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet34\n",
    "arch = resnet34\n",
    "\n",
    "class Debugger(nn.Module): \n",
    "    def forward(self,x): \n",
    "        set_trace()\n",
    "        return x\n",
    "\n",
    "class StdUpsample(nn.Module):\n",
    "    def __init__(self, nin, nout):\n",
    "        super().__init__()\n",
    "        self.conv = nn.ConvTranspose2d(nin, nout, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(nout)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        return self.bn(F.relu(self.conv(x)))\n",
    "\n",
    "flatten_channel = Lambda(lambda x: x[:,])\n",
    "    \n",
    "body = nn.Sequential(*list(arch(True).children())[:-2])\n",
    "head = nn.Sequential(\n",
    "    nn.ReLU(),\n",
    "    StdUpsample(512,256),\n",
    "    StdUpsample(256,256),\n",
    "    StdUpsample(256,256),\n",
    "    StdUpsample(256,256),\n",
    "    nn.ConvTranspose2d(256, 1, 2, stride=2),\n",
    "    flatten_channel\n",
    ")\n",
    "\n",
    "def dice(pred, targs):\n",
    "    pred = (pred>0).float()\n",
    "    return 2. * (pred*targs).sum() / (pred+targs).sum()\n",
    "\n",
    "\n",
    "model = nn.Sequential(body, head)\n",
    "learn = Learner(data, model, metrics=dice)\n",
    "learn.split([model[1]])\n",
    "learn.freeze()\n",
    "apply_init(learn.model[1], nn.init.kaiming_normal_)\n",
    "learn.loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find(learn)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "learn.fit_one_cycle(5, slice(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = learn.lr_range(slice(lr/25,lr)); lrs\n",
    "learn.fit_one_cycle(6, lrs/5, pct_start=0.01, pct_end=0.4, div_factor=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(data.valid_dl))\n",
    "py = learn.model(x)\n",
    "py = py.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(py[0]>0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ax in enumerate(plt.subplots(4,4,figsize=(16,16))[1].flat):\n",
    "    Image(x[i]).show(ax=ax,y=ImageMask(py[i]>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('carvana_simple_128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(size, bs):\n",
    "    tfms = get_transforms(do_flip=True, max_rotate=20, max_zoom=2., max_lighting=0.7, max_warp=0.3,p_affine=0.75)\n",
    "    train_tds, valid_tds, augm_tds = transform_datasets(train_ds, valid_ds, tfms, tfm_y=True, size=size)\n",
    "    data = DataBunch.create(train_tds, valid_tds, bs=bs, dl_tfms=default_norm)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=512\n",
    "bs = 8\n",
    "\n",
    "data = get_data(size, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "learn = Learner(data, model, metrics=dice)\n",
    "learn.loss_fn = nn.BCEWithLogitsLoss()\n",
    "learn.load('carvana_simple_128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(6, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('carvana_simple_512')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
